# continuousf0eval
Continuous Metrics for Evaluating Single-f0 Estimation


## To-Do

- [ ] Section 4 - qualitative example from ikala or medleydb where estimated voicing disagrees with pitch annotation
- [x] 5.1 Crepe + pyin on medleydb-pitch, old + new metrics
- [x] 5.1 MedleyDB + Deep Salience on iKala, old + new metrics
- [x] 5.2 Melodia + Deep Salience on iKala (MDB-melody?) grid of thresholds
- [x] 5.2 Crepe + pyin on MedleyDB-pitch, grid of thresholds
- [x] 5.4 One algorithm (deep salience + ikala), 2 x 2 combo of binary + continous results in new metric, discuss difference
- [ ] 5.3 Look at effect of rescaling confidence values on metrics
- [x] Write code to use normalized energy as a proxy for confidence
- [x] Compute confidence proxy on MedleyDB-Pitch
- [x] Compute confidence proxy on IKala
- [x] Run pYIN (with confidence output) on MedleyDB-Pitch
- [x] Run Crepe on MedleyDB-Pitch (2 files with errors?)
- [x] Run Melodia (with confidence output) on iKala + Orchset + MedleyDB-Melody
- [x] Run Deep Salience on iKala + Orchset + MedleyDB-Melody
- [x] Implement new metrics
